{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data (generated by data_preprocessing.ipynb)\n",
    "groups = pd.read_json('CrossValidation_5%9_group1_Leave1Out+99NegSamples.json')\n",
    "print('num of users: ', len(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model and Make Recommendations\n",
    "K = *** decided by the user ***\n",
    "alpha = *** decided by the user ***\n",
    "beta = *** decided by the user ***\n",
    "gamma = *** decided by the user ***\n",
    "iter_times = *** decided by the user ***\n",
    "num_recommend = *** decided by the user ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five Folds Cross Validation\n",
    "def evaulate_topN_negative_samples(N, recommendation):\n",
    "    match_people = 0\n",
    "    NDCG = 0\n",
    "    pop = 0\n",
    "    for user in range(len(recommendation)):\n",
    "        i_truth = 0\n",
    "        u_recommend = recommendation[user][:N]\n",
    "        if i_truth in u_recommend:\n",
    "            match_people += 1\n",
    "            i_truth_rank = u_recommend.index(i_truth)\n",
    "            NDCG += 1 / np.log2(i_truth_rank + 2)\n",
    "        else:\n",
    "            pass\n",
    "        first_item = u_recommend[0]\n",
    "        pop += dictionary.dfs[first_item]\n",
    "    HR = match_people / len(recommendation)\n",
    "    NDCG = NDCG / len(recommendation)\n",
    "    POP = pop / len(recommendation)\n",
    "    return HR, NDCG, POP\n",
    "\n",
    "TopN_global = np.array([0]*num_recommend)\n",
    "N_items_global = np.array([0]*num_recommend)\n",
    "HRs_global = np.array([0]*num_recommend)\n",
    "NDCGs_global = np.array([0]*num_recommend)\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    # process\n",
    "    str_Train = [str(i)[1:-1].split(', ') for i in groups['Fold' + str(fold) + '_train']]\n",
    "    str_Test = [str(i)[1:-1].split(', ') for i in groups['Fold' + str(fold) + '_test']]\n",
    "    print(' //// Dictionary')\n",
    "    dictionary = corpora.Dictionary(str_Train)\n",
    "    print(' //// num of items:', len(dictionary))\n",
    "    print(' //// dictionary.doc2idx')\n",
    "    pro_Train = [dictionary.doc2idx(i) for i in str_Train]\n",
    "    pro_Test = [dictionary.doc2idx(i) for i in str_Test]\n",
    "    print(' //// Use pro_Train as INPUT and pro_Test as OUTPUT')\n",
    "    \n",
    "    PELDA = PELDA(numTopics=K, alpha, beta, gamma)\n",
    "    PELDA.fit(pro_Train, iter_times)\n",
    "    PELDA.params_estimate()\n",
    "    PELDA.negative_recommend(pro_Test, num_recommend)\n",
    "    recommend = PELDA.read_negative_recommend()\n",
    "\n",
    "    # print evaluation results for each fold\n",
    "    TopN = []\n",
    "    N_items = []\n",
    "    HRs = []\n",
    "    NDCGs = []\n",
    "    for i in tqdm(range(1, num_recommend+1)):\n",
    "        HR, NDCG, POP = evaulate_topN_negative_samples(i, recommend)\n",
    "        TopN.append(i)\n",
    "        HRs.append(HR)\n",
    "        NDCGs.append(NDCG)\n",
    "    results = pd.DataFrame({'TopN': TopN, 'ConversionRate': HRs, 'NDCG': NDCGs})\n",
    "    print(results)\n",
    "    results.to_csv('PELDA_results_'+str(fold)+'.csv', index=False)\n",
    "    \n",
    "    TopN_global += np.array(TopN)\n",
    "    N_items_global += np.array(N_items)\n",
    "    HRs_global += np.array(HRs)\n",
    "    NDCGs_global += np.array(NDCGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Evaluation Results for Five Folds\n",
    "print('////////////   Negative Sample Evaluation  ////////////')\n",
    "results = pd.DataFrame({'TopN': TopN_global/5, 'ConversionRate': HRs_global/5, 'NDCG': NDCGs_global/5})\n",
    "print(results)\n",
    "results.to_csv('PELDA_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
