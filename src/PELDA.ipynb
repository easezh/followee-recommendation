{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train PE-LDA and conduct followee recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Functions\n",
    "def sampleFromDirichlet(alpha):\n",
    "    return np.random.dirichlet(alpha)\n",
    "def sampleFromMultinomial(theta):\n",
    "    theta = theta / np.sum(theta)\n",
    "    a = np.random.multinomial(1, theta)\n",
    "    return ((a!=0).argmax())\n",
    "def sampleFromBeta(gamma):\n",
    "    return np.random.beta(gamma[0], gamma[1])\n",
    "def sampleFromBinomial(psi):\n",
    "    return np.random.binomial(1, psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PE-LDA Gibbs sampler\n",
    "class PELDA:\n",
    "    def __init__(self, numTopics, alpha, beta, gamma):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.numTopics = numTopics\n",
    "\n",
    "    def processProfiles(self, users_lists):\n",
    "        wordOccuranceMatrix = users_lists\n",
    "        self.numDocs = len(wordOccuranceMatrix)\n",
    "        self.words_count = np.max([np.max(i) for i in users_lists]) + 1\n",
    "        self.sum_alpha = self.numTopics * self.alpha\n",
    "        self.sum_beta = self.words_count * self.beta\n",
    "        self.sum_gamma = self.gamma[0] + self.gamma[1]\n",
    "        return wordOccuranceMatrix\n",
    "\n",
    "    def initialize(self, users_lists):\n",
    "        assignVec = [self.alpha] * self.numTopics\n",
    "        for user in range(self.numDocs):\n",
    "            u_list = users_lists[user]\n",
    "            for i, w in enumerate(u_list):  \n",
    "                if i < 1:  # the first item\n",
    "                    trigger = 0\n",
    "                    topic_update = sampleFromMultinomial(assignVec)\n",
    "                else:\n",
    "                    trigger = sampleFromBinomial(0.5)\n",
    "                    if trigger == 0:  # non-sticky\n",
    "                        topic_update = sampleFromMultinomial(assignVec)\n",
    "                    else:  # sticky\n",
    "                        topic_update = self.Z_post[user][i - 1]\n",
    "                self.Z_post[user][i] = topic_update\n",
    "                self.Trigger[user][i] = trigger\n",
    "                w = u_list[i]\n",
    "                # update pseudo-counters\n",
    "                self.n_doc_topic_trigger[user][topic_update][trigger] += 1\n",
    "                self.n_topic_word[w][topic_update] += 1\n",
    "                self.n_doc_trigger[user][trigger] += 1\n",
    "                self.sum_doc[user][trigger] += 1\n",
    "                self.sum_topic[topic_update] += 1\n",
    "\n",
    "    def gibbsSampler(self, user, item):\n",
    "        prob_topictrigger = np.zeros((self.numTopics, 2))\n",
    "        w = self.wordOccuranceMatrix[user][item] \n",
    "        factor_theta_0 = (self.n_doc_topic_trigger[user, :, 0] + self.n_doc_topic_trigger[user, :, 1] + self.alpha) / (\n",
    "                    self.sum_doc[user, 0] + self.sum_doc[user, 1] + self.sum_alpha)\n",
    "        factor_phi_0 = (self.n_topic_word[w, :] + self.beta) / (self.sum_topic + self.sum_beta)\n",
    "        # Gibbs Sampling:\n",
    "        if item < 1:\n",
    "            prob_topictrigger[:, 0] = factor_phi_0 * factor_theta_0\n",
    "            prob_topictrigger[:, 1] *= 0\n",
    "        else:\n",
    "            factor_psi_0 = (self.gamma[1] + self.n_doc_trigger[\n",
    "                user, 0] - 1)\n",
    "            # non-sticky\n",
    "            prob_topictrigger[:, 0] = factor_psi_0 * factor_phi_0 * factor_theta_0\n",
    "            # sticky\n",
    "            prob_topictrigger[:, 1] *= 0\n",
    "            topic_n_1 = self.Z_post[user][item - 1]\n",
    "            factor_phi_1 = (self.n_topic_word[w, topic_n_1] + self.beta) / (self.sum_topic[topic_n_1] + self.sum_beta)\n",
    "            factor_psi_1 = (self.gamma[0] + self.n_doc_trigger[\n",
    "                user, 1])\n",
    "            prob_topictrigger[:, 1][topic_n_1] = factor_psi_1 * factor_phi_1\n",
    "        return prob_topictrigger\n",
    "\n",
    "    def fit(self, users_lists, iter_times):\n",
    "        print('//////////// alpha:', self.alpha, '; beta:', self.beta, '; gamma:', self.gamma, '; K:', self.numTopics)\n",
    "        self.wordOccuranceMatrix = self.processProfiles(users_lists)\n",
    "        # Construct Pseudo-counters:\n",
    "        self.n_doc_trigger = np.zeros((self.numDocs, 2), dtype='int')  # Psi\n",
    "        self.n_doc_topic_trigger = np.zeros((self.numDocs, self.numTopics, 2), dtype='int')  # Theta\n",
    "        self.n_topic_word = np.zeros((self.words_count, self.numTopics), dtype='int')  # Phi\n",
    "        self.sum_doc = np.zeros((self.numDocs, 2), dtype='int')  # theta\n",
    "        self.n_doc = np.zeros(self.numDocs, dtype='int')  # Psi\n",
    "        self.sum_topic = np.zeros(self.numTopics, dtype='int')  # Phi\n",
    "        # Construct saver for the sample results of topic and triggers\n",
    "        self.Z_post = []\n",
    "        self.Trigger = []\n",
    "        for x in range(self.numDocs):\n",
    "            u_list = users_lists[x]\n",
    "            self.n_doc[x] = len(u_list)\n",
    "            self.Z_post.append([0 for i in range(len(u_list))])\n",
    "            self.Trigger.append([0 for i in range(len(u_list))])\n",
    "        # Latent Parameters\n",
    "        self.Theta = np.zeros((self.numDocs, self.numTopics))\n",
    "        self.Phi = np.zeros((self.numTopics, self.words_count))\n",
    "        self.Psi = np.zeros(self.numDocs)\n",
    "        print(\"//////////// Start the Initializations ////////////\")\n",
    "        # Initialize: randomly assign topic and trigger\n",
    "        self.initialize(users_lists)\n",
    "        for iteration in tqdm(range(iter_times)):\n",
    "            for user in range(self.numDocs):\n",
    "                u_list = users_lists[user]\n",
    "                for i in range(len(u_list)):\n",
    "                    # retrieve the topic and trigger\n",
    "                    topic = self.Z_post[user][i]  # i: order in list\n",
    "                    trigger = self.Trigger[user][i]\n",
    "                    w = u_list[i]  # w: item id\n",
    "                    # for this current assignment of k to a term t, Pseudo-counter - 1\n",
    "                    self.n_doc_topic_trigger[user][topic][trigger] -= 1\n",
    "                    self.n_topic_word[w][topic] -= 1\n",
    "                    self.n_doc_trigger[user][trigger] -= 1\n",
    "                    self.sum_doc[user][trigger] -= 1\n",
    "                    self.sum_topic[topic] -= 1\n",
    "                    # gibbs-sampler\n",
    "                    prob_topictrigger = self.gibbsSampler(user, i)\n",
    "                    if i < 1:\n",
    "                        prob_gibbs = prob_topictriggerprob_topictrigger[:, 1][:, 0]\n",
    "                        topic_new = sampleFromMultinomial(prob_gibbs)\n",
    "                        trigger_new = 0 \n",
    "                    else:\n",
    "                        prob_gibbs = prob_topictrigger.flatten('F')\n",
    "                        topic_trigger = sampleFromMultinomial(prob_gibbs)\n",
    "                        if topic_trigger >= self.numTopics:\n",
    "                            topic_new = topic_trigger - self.numTopics\n",
    "                            trigger_new = 1\n",
    "                        else:\n",
    "                            topic_new = topic_trigger\n",
    "                            trigger_new = 0\n",
    "                    # Save topic\n",
    "                    self.Z_post[user][i] = topic_new\n",
    "                    self.Trigger[user][i] = trigger_new\n",
    "                    # Update counters\n",
    "                    self.n_doc_topic_trigger[user][topic_new][trigger_new] += 1\n",
    "                    self.n_topic_word[w][topic_new] += 1\n",
    "                    self.n_doc_trigger[user][trigger_new] += 1\n",
    "                    self.sum_doc[user][trigger_new] += 1\n",
    "                    self.sum_topic[topic_new] += 1\n",
    "\n",
    "    def params_estimate(self):\n",
    "        print(\"////////////   Estimate the Posterior  ////////////\")\n",
    "        ## Theta & Psi\n",
    "        for user in range(self.numDocs):\n",
    "            self.Theta[user] = (self.n_doc_topic_trigger[user, :, 0] + self.n_doc_topic_trigger[user, :, 1] + self.alpha) / (\n",
    "                        self.sum_doc[user, 0] + self.sum_doc[user, 1] + self.sum_alpha)\n",
    "            self.Psi[user] = (self.gamma[0] + self.n_doc_trigger[user, 1]) / (self.n_doc[user] - 1 + self.sum_gamma)\n",
    "        ## Phi\n",
    "        for topic in range(self.numTopics):\n",
    "            self.Phi[topic] = (self.n_topic_word[:, topic] + self.beta) / (self.sum_topic[topic] + self.sum_beta)\n",
    "\n",
    "    def negative_recommend(self, negative_sample, TopN):\n",
    "        print('////////////   Negative Sample Recommendation  ////////////')\n",
    "        self.recommendation = []\n",
    "        for user in tqdm(range(self.numDocs)):\n",
    "            p_zu = self.Theta[user]\n",
    "            psi = self.Psi[user]\n",
    "            topic_n_1 = self.Z_post[user][-1]\n",
    "            u_negative = negative_sample[user]\n",
    "            prob_list = np.zeros(len(u_negative))\n",
    "            for i in range(len(u_negative)):\n",
    "                item = u_negative[i]\n",
    "                if item != -1:\n",
    "                    p_gz = self.Phi[:, item]\n",
    "                    prob_list[i] = (1 - psi) * np.sum(p_gz * p_zu) + psi * p_gz[topic_n_1]\n",
    "                else:  # the item only appears in Testset,\n",
    "                    prob_list[i] = 0\n",
    "            a = prob_list.tolist()\n",
    "            recommend_ranklist = (np.argsort(-np.array(a))[: TopN]).tolist()\n",
    "            self.recommendation.append(recommend_ranklist)\n",
    "\n",
    "    def read_Theta(self):\n",
    "        return self.Theta\n",
    "\n",
    "    def read_Phi(self):\n",
    "        return self.Phi\n",
    "\n",
    "    def read_Psi(self):\n",
    "        return self.Psi\n",
    "    \n",
    "    def read_negative_recommend(self):\n",
    "        return self.recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. PE-LDA was implemented in C in our experiments. It is available based on reasonable request."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
